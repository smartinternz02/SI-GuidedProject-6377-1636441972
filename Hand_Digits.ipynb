{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d626be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shiv Taneja\n",
    "#VIT Bhopal\n",
    "#shiv.taneja2019@vitbhopal.ac.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2783211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238db201",
   "metadata": {},
   "source": [
    "## Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb161a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73fdaee3",
   "metadata": {},
   "source": [
    "Image Augmentation Techniques\n",
    "1. Image Scaling\n",
    "2. Image Shifting\n",
    "3. Image Rotation\n",
    "4. Image Flipping\n",
    "5. Image Noising\n",
    "6. Image Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad1de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_data=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6b9f9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 10 classes.\n",
      "Found 50 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_data.flow_from_directory(r\"Hand_digits\\traindata\",target_size=(96,96),batch_size=10,class_mode=\"categorical\")\n",
    "x_test=test_data.flow_from_directory(r\"Hand_digits\\testdata\",target_size=(96,96),batch_size=10,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "738c1926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbc01ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be18d8",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9961bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2914452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add convoultion layer(no.of filters,filter size,input shape,activation function)\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(96,96,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23013067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add maxpooling(pool_size)\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11200b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten layer---input layer of ann\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0e4d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer(units,activation fucniton)\n",
    "model.add(Dense(units=150,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c9939ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer(no.of neurons,activation function)\n",
    "model.add(Dense(units=10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b26c232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 70688)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 150)               10603350  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1510      \n",
      "=================================================================\n",
      "Total params: 10,605,756\n",
      "Trainable params: 10,605,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "154712a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter values and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d528ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model(optimizer,loss,metric)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bdc27eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 8.3330 - acc: 0.1000 - val_loss: 2.7474 - val_acc: 0.1000\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 2.4500 - acc: 0.1187 - val_loss: 2.3248 - val_acc: 0.1000\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 2.2751 - acc: 0.1250 - val_loss: 2.2617 - val_acc: 0.1200\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 2.1753 - acc: 0.2500 - val_loss: 2.2062 - val_acc: 0.1600\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 2.1127 - acc: 0.2875 - val_loss: 2.1494 - val_acc: 0.2600\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 1.9480 - acc: 0.3438 - val_loss: 2.0460 - val_acc: 0.2600\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 1.7961 - acc: 0.5000 - val_loss: 1.9337 - val_acc: 0.3400\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 1.6982 - acc: 0.4938 - val_loss: 1.8679 - val_acc: 0.3800\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 1.5317 - acc: 0.5562 - val_loss: 1.8020 - val_acc: 0.3800\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 1.4047 - acc: 0.6313 - val_loss: 1.7386 - val_acc: 0.4200\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 1.2971 - acc: 0.6062 - val_loss: 1.8551 - val_acc: 0.3600\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 1.1984 - acc: 0.6187 - val_loss: 1.7668 - val_acc: 0.3400\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.1602 - acc: 0.6687 - val_loss: 1.8563 - val_acc: 0.4000\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 1.0726 - acc: 0.7000 - val_loss: 1.6530 - val_acc: 0.5000\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.0045 - acc: 0.6938 - val_loss: 1.7010 - val_acc: 0.4400\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.9439 - acc: 0.7375 - val_loss: 1.6737 - val_acc: 0.5000\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.8323 - acc: 0.7500 - val_loss: 1.6021 - val_acc: 0.4800\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.7820 - acc: 0.7937 - val_loss: 1.5612 - val_acc: 0.5200\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.6744 - acc: 0.7812 - val_loss: 1.6998 - val_acc: 0.4800\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.6548 - acc: 0.8500 - val_loss: 1.5220 - val_acc: 0.4800\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.6157 - acc: 0.7875 - val_loss: 1.4681 - val_acc: 0.5200\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.5809 - acc: 0.8500 - val_loss: 1.5193 - val_acc: 0.5600\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.5174 - acc: 0.8687 - val_loss: 1.6251 - val_acc: 0.5400\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.5476 - acc: 0.8438 - val_loss: 1.4463 - val_acc: 0.5200\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.5723 - acc: 0.8250 - val_loss: 1.4605 - val_acc: 0.5200\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.5108 - acc: 0.8813 - val_loss: 1.5062 - val_acc: 0.5200\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.4017 - acc: 0.8875 - val_loss: 1.3983 - val_acc: 0.5600\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.4716 - acc: 0.8938 - val_loss: 1.4759 - val_acc: 0.5600\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.3563 - acc: 0.9312 - val_loss: 1.5988 - val_acc: 0.5600\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.4054 - acc: 0.8750 - val_loss: 1.5157 - val_acc: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22396b26b08>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model(x_train,steps per epoch,no.of epochs,vaidation data=test data)\n",
    "model.fit(x_train,steps_per_epoch=16,epochs=30,validation_steps=5,validation_data=x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f4ad9f",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42551968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"hand_digit.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86beadde",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6714833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e41f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\shiv taneja\\AppData\\Local\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"hand_digit.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09469dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 96, 96, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img(r\"Hand_digits\\sample1.png\",target_size=(96,96))\n",
    "s1=image.img_to_array(img)\n",
    "s1=np.expand_dims(s1,axis=0)\n",
    "s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4269f12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGAAAABgCAIAAABt+uBvAAAA40lEQVR4nO3cQQ3AQBDDwNvy53xFUPnZfcwgiAwgc+89fHv+HrCdQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAp7A83M3xPO2RxoCYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQGFvoCUns3sDLSFQECgIFAQKAgWBgkBBoCBQECgIFAQKAgWBgkBBoCBQECi8tLsGvfnJtsYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=96x96 at 0x223970ADF48>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=[0,1,2,3,4,5,6,7,8,9]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f1b55d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(Prediction): 1\n"
     ]
    }
   ],
   "source": [
    "result=index[np.argmax(model.predict(s1),axis=1)[0]]\n",
    "print(\"Result(Prediction):\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "59730d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 96, 96, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img(\"Hand_digits\\sample6.png\",target_size=(96,96))\n",
    "s2=image.img_to_array(img)\n",
    "s2=np.expand_dims(s2,axis=0)\n",
    "s2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba56bf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=96x96 at 0x223970CBF88>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a4552c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(Prediction): 6\n"
     ]
    }
   ],
   "source": [
    "result=index[np.argmax(model.predict(s2),axis=1)[0]]\n",
    "print(\"Result(Prediction):\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3bbf9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img(\"Hand_digits\\sample2.png\",target_size=(96,96))\n",
    "s3=image.img_to_array(img)\n",
    "s3=np.expand_dims(s3,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "069e36ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=96x96 at 0x223970ADEC8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4efac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(Prediction): 2\n"
     ]
    }
   ],
   "source": [
    "result=index[np.argmax(model.predict(s3),axis=1)[0]]\n",
    "print(\"Result(Prediction):\",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348c8b1",
   "metadata": {},
   "source": [
    "# End! Thank You!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
